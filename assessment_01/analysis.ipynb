{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e696986",
   "metadata": {},
   "source": [
    "# ðŸ“Š Analysis: Column Mapping Justification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39822bf",
   "metadata": {},
   "source": [
    "This notebook explores the statistical and structural relationships between the columns to justify the inferred mapping."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e63918",
   "metadata": {},
   "source": [
    "# Finding volume\n",
    "Since volume is the number of traded stocks, it must be an integer value and greater than all other values in the row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e11bf76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "mapping = pd.read_json(\"mapping.json\")\n",
    "df = pd.read_csv(\"02_sample_data_with_fabricated_columns.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc2ff110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutronCount is volume\n"
     ]
    }
   ],
   "source": [
    "is_integer = (df[\"neutronCount\"] % 1 == 0).all()\n",
    "other_cols = df.drop(columns=[\"neutronCount\"])\n",
    "is_larger = (df[\"neutronCount\"] > other_cols.max(axis=1)).all()\n",
    "if (is_integer and is_larger):\n",
    "    print(\"neutronCount is volume\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f1945c",
   "metadata": {},
   "source": [
    "# Finding high and low\n",
    "We see that 2 columns - `gamma` and `omega` are greater than and less than (resprectively) every other remanining column, except `pulse`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f47d7dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma is high\n",
      "omega is low\n"
     ]
    }
   ],
   "source": [
    "dx = df[\"deltaX\"]\n",
    "gamma = df[\"gamma\"]\n",
    "omega = df[\"omega\"]\n",
    "flux = df[\"flux\"]\n",
    "pulse = df[\"pulse\"]\n",
    "\n",
    "for a, b, c, d in zip(dx, gamma, omega, flux):\n",
    "    if b < a or b < c or b < d:\n",
    "        print(\"Violation!!\")\n",
    "    \n",
    "print(\"gamma is high\")\n",
    "\n",
    "for a, b, c, d in zip(dx, gamma, omega, flux):\n",
    "    if a < c or b < c or d < c:\n",
    "        print(\"Violation!!\")\n",
    "    \n",
    "print(\"omega is low\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa747adb",
   "metadata": {},
   "source": [
    "Since low <= open <= high and low <= close <= high, `pulse` must be price, since it is the only column to not follow this trend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565cfe93",
   "metadata": {},
   "source": [
    "Now we are tasked with mapping `deltaX` and `flux` to open and close. To do this we use the following methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37614a7e",
   "metadata": {},
   "source": [
    "# Using regression model\n",
    "* We can use the data of the past days to predict the present movement of the stock. Thus, we fit a regression model to predict the change in opening price given the momentum (close - open) of the past 4 days.\n",
    "* The hypothesis is that positive momentum should cause growth and negative momentum should cause decline. Thus, if we use the correct mappings, we should get positive values of the coefficients.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3500016b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.000\n",
      "Model:                            OLS   Adj. R-squared:                  0.000\n",
      "Method:                 Least Squares   F-statistic:                     1.583\n",
      "Date:                Mon, 14 Jul 2025   Prob (F-statistic):              0.176\n",
      "Time:                        01:17:13   Log-Likelihood:            -4.3248e+05\n",
      "No. Observations:              499995   AIC:                         8.650e+05\n",
      "Df Residuals:                  499990   BIC:                         8.650e+05\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.0006      0.001     -0.721      0.471      -0.002       0.001\n",
      "x1            -0.0041      0.003     -1.423      0.155      -0.010       0.002\n",
      "x2             0.0016      0.003      0.560      0.576      -0.004       0.007\n",
      "x3             0.0034      0.003      1.173      0.241      -0.002       0.009\n",
      "x4             0.0047      0.003      1.620      0.105      -0.001       0.010\n",
      "==============================================================================\n",
      "Omnibus:                        6.655   Durbin-Watson:                   2.246\n",
      "Prob(Omnibus):                  0.036   Jarque-Bera (JB):                6.617\n",
      "Skew:                          -0.005   Prob(JB):                       0.0366\n",
      "Kurtosis:                       2.986   Cond. No.                         3.54\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for i in range (5, len(dx)):\n",
    "    nx = []\n",
    "    for j in range (4):\n",
    "        nx.append(-(dx[i-5+j] - flux[i-5+j]))\n",
    "\n",
    "\n",
    "    X.append(nx)\n",
    "    y.append(dx[i] - dx[i-1])\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74a6c3c",
   "metadata": {},
   "source": [
    "# Observations\n",
    "* We see that the coefficients are positive, albeit very small. Also, recent days get a greater coefficient than older ones (which is expected).\n",
    "* To get confidence values, we check the number of predictions for which the parity (+ve/-ve) matches the actual parity. This number is very close to 0.5 (random chance), but shows a small bias towards `deltaX` ~ open and `flux` ~ close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50809b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5017030170301703\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X)\n",
    "conf = sum(a * b > 0 for a, b in zip(y, y_pred)) / len(y_pred)\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e182b0a",
   "metadata": {},
   "source": [
    "## A Self-Defined Custom Sliding Window DP Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7a5b19",
   "metadata": {},
   "source": [
    "### Working of the DP Algorithm\n",
    "\n",
    "1. **Find candidates**\n",
    "   - Figures out which columns could be Open or Close:\n",
    "`oc_candidates = all columns MINUS known High, Low, Price and Volume.`\n",
    "\n",
    "2. **Define all possible (Open, Close) pairs**\n",
    "\n",
    "3. **Run a dynamic programming loop**\n",
    "\n",
    "   - For each time step (row in the data):\n",
    "       - For each possible (Open, Close) pair:\n",
    "           - Compute the cost of transitioning from the previous pair to this one.\n",
    "           - Cost = difference between todayâ€™s Open and yesterdayâ€™s Close, plus an extra penalty if you switch mappings.\n",
    "   - Store the minimum cost path.\n",
    "\n",
    "4. **Backtrack**\n",
    "   - After the forward pass, backtrace to get the optimal sequence of states (mappings).\n",
    "\n",
    "5. **Find the most frequent mapping**\n",
    "   - The most common (Open, Close) pair along the optimal path is assumed to be the real mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f262e96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic Programming Solver for Open/Close\n",
      "Candidates for Open/Close: ['deltaX', 'flux']\n",
      "Number of possible states (mappings): 2\n",
      "  State 0: Open=deltaX, Close=flux\n",
      "  State 1: Open=flux, Close=deltaX\n",
      "\n",
      "Running forward pass of the Viterbi algorithm...\n",
      "Processing timestep 10000/500000\n",
      "Processing timestep 20000/500000\n",
      "Processing timestep 30000/500000\n",
      "Processing timestep 40000/500000\n",
      "Processing timestep 50000/500000\n",
      "Processing timestep 60000/500000\n",
      "Processing timestep 70000/500000\n",
      "Processing timestep 80000/500000\n",
      "Processing timestep 90000/500000\n",
      "Processing timestep 100000/500000\n",
      "Processing timestep 110000/500000\n",
      "Processing timestep 120000/500000\n",
      "Processing timestep 130000/500000\n",
      "Processing timestep 140000/500000\n",
      "Processing timestep 150000/500000\n",
      "Processing timestep 160000/500000\n",
      "Processing timestep 170000/500000\n",
      "Processing timestep 180000/500000\n",
      "Processing timestep 190000/500000\n",
      "Processing timestep 200000/500000\n",
      "Processing timestep 210000/500000\n",
      "Processing timestep 220000/500000\n",
      "Processing timestep 230000/500000\n",
      "Processing timestep 240000/500000\n",
      "Processing timestep 250000/500000\n",
      "Processing timestep 260000/500000\n",
      "Processing timestep 270000/500000\n",
      "Processing timestep 280000/500000\n",
      "Processing timestep 290000/500000\n",
      "Processing timestep 300000/500000\n",
      "Processing timestep 310000/500000\n",
      "Processing timestep 320000/500000\n",
      "Processing timestep 330000/500000\n",
      "Processing timestep 340000/500000\n",
      "Processing timestep 350000/500000\n",
      "Processing timestep 360000/500000\n",
      "Processing timestep 370000/500000\n",
      "Processing timestep 380000/500000\n",
      "Processing timestep 390000/500000\n",
      "Processing timestep 400000/500000\n",
      "Processing timestep 410000/500000\n",
      "Processing timestep 420000/500000\n",
      "Processing timestep 430000/500000\n",
      "Processing timestep 440000/500000\n",
      "Processing timestep 450000/500000\n",
      "Processing timestep 460000/500000\n",
      "Processing timestep 470000/500000\n",
      "Processing timestep 480000/500000\n",
      "Processing timestep 490000/500000\n",
      "\n",
      "--- Results ---\n",
      "The most frequent mapping found across the entire dataset was:\n",
      "Optimal Mapping\n",
      "O=deltaX, C=flux    266973\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import permutations\n",
    "\n",
    "DATA_FILE_PATH = \"02_sample_data_with_fabricated_columns.csv\"\n",
    "\n",
    "KNOWN_HIGH = 'gamma'\n",
    "KNOWN_LOW = 'omega'\n",
    "KNOWN_VOLUME = 'neutronCount'\n",
    "KNOWN_PRICE = 'pulse'\n",
    "\n",
    "def solve_open_close_with_dp(file_path, high_col, low_col, volume_col, price_column, switching_penalty=0.1):\n",
    "    print(\"Dynamic Programming Solver for Open/Close\")\n",
    "    \n",
    "    df = pd.read_csv(file_path)\n",
    "    if 'Unnamed: 0' in df.columns:\n",
    "        df = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "    known_cols = [high_col, low_col, volume_col, price_column]\n",
    "    oc_candidates = [c for c in df.columns if c not in known_cols]\n",
    "    \n",
    "    states = list(permutations(oc_candidates, 2))\n",
    "    num_states = len(states)\n",
    "    num_timesteps = len(df)\n",
    "    \n",
    "    print(f\"Candidates for Open/Close: {oc_candidates}\")\n",
    "    print(f\"Number of possible states (mappings): {num_states}\")\n",
    "    for i, state in enumerate(states):\n",
    "        print(f\"  State {i}: Open={state[0]}, Close={state[1]}\")\n",
    "\n",
    "    # cost_matrix[t, k]: min cost to be in state k at time t\n",
    "    # backpointer_matrix[t, k]: which state at t-1 led to the min cost for state k at t\n",
    "    cost_matrix = np.full((num_timesteps, num_states), np.inf)\n",
    "    backpointer_matrix = np.zeros((num_timesteps, num_states), dtype=int)\n",
    "    \n",
    "    # At t=0, the cost to be in any state is 0 (no previous day to compare to)\n",
    "    cost_matrix[0, :] = 0\n",
    "\n",
    "    print(\"\\nRunning forward pass of the Viterbi algorithm...\")\n",
    "    for t in range(1, num_timesteps):\n",
    "        if t % 10000 == 0:\n",
    "            print(f\"Processing timestep {t}/{num_timesteps}\")\n",
    "            \n",
    "        for j, current_state in enumerate(states):\n",
    "            open_j = current_state[0]\n",
    "            \n",
    "            min_cost = np.inf\n",
    "            best_prev_state_idx = -1\n",
    "            \n",
    "            for i, prev_state in enumerate(states):\n",
    "                close_i = prev_state[1]\n",
    "                \n",
    "                # Cost = Previous Path Cost + Transition Cost + Switching Penalty\n",
    "                transition_cost = abs(df[open_j].iloc[t] - df[close_i].iloc[t-1])\n",
    "                penalty = switching_penalty if i != j else 0\n",
    "                \n",
    "                total_cost = cost_matrix[t-1, i] + transition_cost + penalty\n",
    "                \n",
    "                if total_cost < min_cost:\n",
    "                    min_cost = total_cost\n",
    "                    best_prev_state_idx = i\n",
    "            \n",
    "            cost_matrix[t, j] = min_cost\n",
    "            backpointer_matrix[t, j] = best_prev_state_idx\n",
    "            \n",
    "    optimal_path = np.zeros(num_timesteps, dtype=int)\n",
    "    \n",
    "    optimal_path[-1] = np.argmin(cost_matrix[-1, :])\n",
    "    \n",
    "    for t in range(num_timesteps - 2, -1, -1):\n",
    "        optimal_path[t] = backpointer_matrix[t + 1, optimal_path[t + 1]]\n",
    "\n",
    "    print(\"\\n--- Results ---\")\n",
    "    path_in_words = [f\"O={states[i][0]}, C={states[i][1]}\" for i in optimal_path]\n",
    "    results_df = pd.DataFrame({'Optimal Mapping': path_in_words})\n",
    "    \n",
    "    most_likely_mapping_counts = results_df['Optimal Mapping'].value_counts()\n",
    "    \n",
    "    print(\"The most frequent mapping found across the entire dataset was:\")\n",
    "    print(most_likely_mapping_counts.head(1))\n",
    "    \n",
    "    return most_likely_mapping_counts\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    most_likely_mapping = solve_open_close_with_dp(DATA_FILE_PATH, high_col=KNOWN_HIGH, low_col=KNOWN_LOW, volume_col=KNOWN_VOLUME, price_column=KNOWN_PRICE,switching_penalty=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fe0ea3",
   "metadata": {},
   "source": [
    "The above also shows that `deltaX` is open and `flux` is close, but that is true for only 266973 / 500000 samples, which is roughly 0.53 of the total. This is again, very close to random chance (0.5), but shows a small bias towards our previous finding (using the regression model). Thus, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d94544",
   "metadata": {},
   "source": [
    "`deltaX`: open  \n",
    "`flux`: close"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
